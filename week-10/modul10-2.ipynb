{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Praktikum 2\n",
        "Generator Teks dengan RNN"
      ],
      "metadata": {
        "id": "dVW8MYcBpElb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ],
      "metadata": {
        "id": "QCCAlTg2pFVq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# URL ke file teks Shakespeare\n",
        "url = 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt'\n",
        "\n",
        "# Download file teks\n",
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBrP2t58pgVs",
        "outputId": "c712d665-3e2b-423e-819c-6c1061124ed8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Data"
      ],
      "metadata": {
        "id": "HnBjSdE-rB5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dwbdd1nGrCiZ",
        "outputId": "4cc9a0ce-0969-4a3b-f7aa-2f81ae7ed219"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 1115394 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHslRoo6rFz5",
        "outputId": "3284680e-4896-4393-c8df-8d89c53cf120"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFj7U9AirIm_",
        "outputId": "98d7c338-091c-447c-9c02-cbb5d3d45a85"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65 unique characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Olah Teks"
      ],
      "metadata": {
        "id": "CtHMLo7QrMhZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vectorize Teks\n",
        "\n",
        "\n",
        "Sebelum training, Anda perlu mengonversi string menjadi representasi numerik. tf.keras.layers.StringLookup dapat mengubah setiap karakter menjadi ID numerik. Caranya adalah teks akan dipecah menjadi token terlebih dahulu."
      ],
      "metadata": {
        "id": "nBC6ZA8hrOUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "example_texts = ['abcdef', 'xyz']\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "\n",
        "print(chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beBUZ8-grRvT",
        "outputId": "f28ad1d2-907d-46e2-e7f2-505e9caa8e11"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f'], [b'x', b'y', b'z']]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sekarang buat tf.keras.layers.StringLookup layer:"
      ],
      "metadata": {
        "id": "t0y9G3sxrsKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixed code\n",
        "ids_from_chars = tf.keras.layers.StringLookup(\n",
        "    vocabulary=list(vocab),\n",
        "    mask_token=None\n",
        ")"
      ],
      "metadata": {
        "id": "ITMhd0d9rs3L"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "perintah diatas mengconvert token menjadi id"
      ],
      "metadata": {
        "id": "b3_CCGyyvVse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ids = ids_from_chars(chars)\n",
        "ids"
      ],
      "metadata": {
        "id": "EyDTGdSZvij9",
        "outputId": "85664231-5fed-47b5-cc2b-688615235050",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45], [63, 64, 65]]>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Karena tujuan tutorial ini adalah untuk menghasilkan teks, penting juga untuk membalikkan representasi ini. Untuk ini Anda dapat menggunakan kode tf.keras.layers.StringLookup(..., invert=True).\n",
        "Catatan: pada kode ini, daripada meneruskan kosakata asli yang dihasilkan dengan diurutkan(set(teks)) gunakan metode get_vocabulary() dari tf.keras.layers.StringLookup sehingga token [UNK] disetel dengan cara yang sama."
      ],
      "metadata": {
        "id": "hVQ7nyQEvu6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ],
      "metadata": {
        "id": "sZSLm46mvyl3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lapisan ini mengconvert kembali karakter dari vektor ID, dan mengembalikannya sebagai karakter tf.RaggedTensor:"
      ],
      "metadata": {
        "id": "r7-UteVcv172"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chars = chars_from_ids(ids)\n",
        "chars"
      ],
      "metadata": {
        "id": "MkpxMlrYv2iI",
        "outputId": "ccbda6a8-0196-4513-ba35-93594502925a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Anda dapat menggunakan tf.strings.reduce_join untuk menggabungkan kembali karakter menjadi string."
      ],
      "metadata": {
        "id": "qGf0ONhTwEpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy()"
      ],
      "metadata": {
        "id": "UCdcvniQwFSg",
        "outputId": "8b7cfd9d-6a39-4a29-8781-d4c5fedd48f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'abcdef', b'xyz'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixed code\n",
        "def text_from_ids(ids):\n",
        "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "metadata": {
        "id": "cf9cwQQpxNvd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediksi\n",
        "\n",
        "Diberikan sebuah karakter, atau serangkaian karakter, karakter apa yang paling mungkin berikutnya? Ini adalah tugas yang harus Anda latih agar model dapat melakukannya. Masukan ke model akan berupa urutan karakter, dan Anda melatih model untuk memprediksi keluaran berupa karakter berikut pada setiap langkah waktu. Karena RNN mempertahankan keadaan internal yang bergantung pada elemen yang terlihat sebelumnya, mengingat semua karakter dihitung hingga saat ini, karakter apa selanjutnya?\n",
        "\n",
        "\n",
        "Membuat Trianing Set dan Target\n",
        "\n",
        "Selanjutnya bagilah teks menjadi contoh sequence. Setiap masukan sequence akan berisi karakter seq_length dari teks. Untuk setiap masukan sequence, target prediksi berisi teks dengan panjang yang sama, hanya digeser satu karakter ke kanan. Jadi, bagi teks menjadi beberapa bagian seq_length+1. Misalnya, seq_length adalah 4 dan teks kita adalah \"Hello\". Urutan masukannya adalah \"Hell\", dan urutan targetnya adalah \"ello\". Untuk melakukan ini, pertama-tama gunakan fungsi tf.data.Dataset.from_tensor_slices untuk mengonversi vektor teks menjadi aliran indeks karakter."
      ],
      "metadata": {
        "id": "hh5sv2qFxlVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ],
      "metadata": {
        "id": "aB6Pw-jjxqld",
        "outputId": "24d32fe4-508f-49cc-f8d6-c5e6b155aaee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ],
      "metadata": {
        "id": "vNk8QBJkxsBY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ],
      "metadata": {
        "id": "fAKXCvFTxyME",
        "outputId": "527ef4df-e2cb-4a27-a04f-d257ac2d4aae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 100"
      ],
      "metadata": {
        "id": "FGQ30bv8x0Rk"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metode batch memungkinkan Anda dengan mudah mengonversi karakter individual ini menjadi urutan ukuran yang diinginkan."
      ],
      "metadata": {
        "id": "aq8cxnuDx5IB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ],
      "metadata": {
        "id": "OTZd0ivqyQhT",
        "outputId": "4d7157fd-bfe1-4ed4-93a1-82089e5d357e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "akan lebih mudah untuk melihat apa yang dilakukan jika Anda menggabungkan token kembali menjadi string:"
      ],
      "metadata": {
        "id": "Tx-87xTIyXs9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for seq in sequences.take(5):\n",
        "    print(text_from_ids(seq).numpy())"
      ],
      "metadata": {
        "id": "-oanDg6-ySpX",
        "outputId": "32be1fca-07db-4f2b-ecc2-117a530a1d3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Untuk pelatihan, Anda memerlukan kumpulan data pasangan (input, label). Dimana input dan label merupakan urutan. Pada setiap langkah waktu, inputnya adalah karakter saat ini dan labelnya adalah karakter berikutnya. Berikut adalah fungsi yang mengambil urutan sebagai masukan, menduplikasi, dan menggesernya untuk menyelaraskan masukan dan label untuk setiap langkah waktu:"
      ],
      "metadata": {
        "id": "Lvke_PfVyduY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ],
      "metadata": {
        "id": "oZTn57q5yegi"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "metadata": {
        "id": "NRXhzMywygHF",
        "outputId": "b9ca785b-83fe-4efc-a52e-f2dffd8ff2c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = sequences.map(split_input_target)"
      ],
      "metadata": {
        "id": "A_J5KZQEyh2l"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ],
      "metadata": {
        "id": "tykRneCeyjkC",
        "outputId": "2d5e1c69-6d4a-4859-ae53-62d37aa03e8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Membuat Batch Training\n",
        "\n",
        "Anda menggunakan tf.data untuk membagi teks menjadi sequence yang dapat diatur. Namun sebelum memasukkan data ini ke dalam model, Anda perlu mengacak data dan mengemasnya ke dalam batch."
      ],
      "metadata": {
        "id": "gh-270xhync9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "id": "1e4LuBMvypCD",
        "outputId": "11435878-79ac-4410-bdf2-9e8d9bfd6776",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Buat Model"
      ],
      "metadata": {
        "id": "s06U98tRyxNT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "metadata": {
        "id": "sbmD1njsytnj"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ],
      "metadata": {
        "id": "URCtbfVUy2Nk"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "metadata": {
        "id": "CswwqFfYy2l9"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uji Model\n",
        "\n",
        "Coba jalankan model dan cek apakah sidah sesuai dengan output\n",
        "\n",
        "pertama, cek bentuk dari output"
      ],
      "metadata": {
        "id": "-j9SNYKWy7Wn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "metadata": {
        "id": "SCVqEKZty9Is",
        "outputId": "82ed7f13-b035-4b71-a7d3-c1f82eb294c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dalam contoh di atas, panjang urutan masukan adalah 100 tetapi model dapat dijalankan pada masukan dengan panjang berapa pun:"
      ],
      "metadata": {
        "id": "x8uze9A6zH6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "TGUtKIgLzJZF",
        "outputId": "c52af4d9-5bc8-441d-af9b-72beef04ae35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  16896     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  67650     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4022850 (15.35 MB)\n",
            "Trainable params: 4022850 (15.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Untuk mendapatkan prediksi aktual dari model, Anda perlu mengambil sampel dari distribusi keluaran, untuk mendapatkan indeks karakter aktual. Distribusi ini ditentukan oleh logit pada kosakata karakter. Catatan: Penting untuk mengambil sampel dari distribusi ini karena mengambil argmax dari distribusi tersebut dapat dengan mudah membuat model terjebak dalam infinote loop. Cobalah untuk contoh pertama di batch:"
      ],
      "metadata": {
        "id": "_H9o2UPHzN_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ],
      "metadata": {
        "id": "YvzWVvYXzOYm"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ],
      "metadata": {
        "id": "fB1euezZzP3f",
        "outputId": "b5328a3a-9803-4da4-8fa0-6f05cb018609",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " b'Berkeley, and Seymour;\\nNone else of name and noble estimate.\\n\\nNORTHUMBERLAND:\\nHere come the Lords of'\n",
            "\n",
            "Next Char Predictions:\n",
            " b\"e&jIWsEpfDEN&r,ybW3jPqyjevV FddByI:WXCfP.vDhJ-'zjcj&iW&[UNK]ibB!NbDuY\\nK,.kOjZDiqYq3Xp$VF;I[UNK]hH3BOVx&ZYwoW\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Model"
      ],
      "metadata": {
        "id": "qlVtNCOlzbyl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada titik ini permasalahan dapat dianggap sebagai permasalahan klasifikasi standar. Permasalahan dapat disimpulkan dengan : Berdasarkan status RNN sebelumnya, dan masukan langkah kali ini, prediksi kelas karakter berikutnya.\n",
        "\n",
        "Tambahan optimizer dan fungsi loss\n",
        "\n",
        "loss function tf.keras.losses.sparse_categorical_crossentropy standar berfungsi dalam kasus ini karena diterapkan di seluruh dimensi terakhir prediksi. Karena model Anda mengembalikan logits, Anda perlu mengatur flag from_logits.\n"
      ],
      "metadata": {
        "id": "mfgdkOfYzgCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "OOQcj01Tzg6g"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ],
      "metadata": {
        "id": "x78rFxGRzjpU",
        "outputId": "2d7ad1b0-7c3b-4744-dea8-6eed6a32d1f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.1904216, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model yang baru diinisialisasi tidak boleh terlalu yakin dengan dirinya sendiri, semua log keluaran harus memiliki besaran yang sama. Untuk mengonfirmasi hal ini, Anda dapat memeriksa bahwa eksponensial dari loss rata-rata harus kira-kira sama dengan ukuran kosakata. Loss yang jauh lebih tinggi berarti model tersebut yakin akan jawaban yang salah, dan memiliki inisialisasi yang buruk:"
      ],
      "metadata": {
        "id": "15SVeI7Ezsfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.exp(example_batch_mean_loss).numpy()"
      ],
      "metadata": {
        "id": "xC__k8lJzu08",
        "outputId": "a364bde0-87f5-48a3-cb0a-c6bd0ad4e9fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66.05063"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Konfigurasikan prosedur pelatihan menggunakan metode tf.keras.Model.compile. Gunakan tf.keras.optimizers.Adam dengan argumen default dan fungsi loss."
      ],
      "metadata": {
        "id": "4A9P9mbtz0Wf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "metadata": {
        "id": "k6mIKzWuz0ye"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Konfigurasi Checkpoints\n",
        "\n",
        "Gunakan tf.keras.callbacks.ModelCheckpoint untuk memastikan bahwa checkpoint disimpan selama pelatihan:"
      ],
      "metadata": {
        "id": "47mPg37Tz6Hs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "metadata": {
        "id": "j8zg_4_Jz7l2"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lakukan Proses Training\n",
        "\n",
        "Agar waktu pelatihan tidak terlalu lama, gunakan 10 epoch untuk melatih model. Di Colab, setel runtime ke GPU untuk pelatihan yang lebih cepat."
      ],
      "metadata": {
        "id": "PBQkD0w50AID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10"
      ],
      "metadata": {
        "id": "XgdGZWxd0A4s"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "id": "tzUkixXZ0CUm",
        "outputId": "1ae17f58-b252-4cd3-f9c2-6c0749266f02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "172/172 [==============================] - 929s 5s/step - loss: 2.6971\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 896s 5s/step - loss: 1.9761\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 914s 5s/step - loss: 1.6981\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 912s 5s/step - loss: 1.5394\n",
            "Epoch 5/10\n",
            "172/172 [==============================] - 915s 5s/step - loss: 1.4426\n",
            "Epoch 6/10\n",
            "172/172 [==============================] - 917s 5s/step - loss: 1.3750\n",
            "Epoch 7/10\n",
            "172/172 [==============================] - 922s 5s/step - loss: 1.3225\n",
            "Epoch 8/10\n",
            "172/172 [==============================] - 912s 5s/step - loss: 1.2774\n",
            "Epoch 9/10\n",
            "172/172 [==============================] - 915s 5s/step - loss: 1.2370\n",
            "Epoch 10/10\n",
            "172/172 [==============================] - 913s 5s/step - loss: 1.1965\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Teks"
      ],
      "metadata": {
        "id": "X63kWXpUsBth"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cara termudah untuk menghasilkan teks dengan model ini adalah dengan menjalankannya dalam loop, dan menyimpan status internal model saat Anda menjalankannya."
      ],
      "metadata": {
        "id": "8m3PgFimsGtV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setiap kali Anda memanggil model, Anda memasukkan beberapa teks dan state internal. Model mengembalikan prediksi untuk karakter berikutnya dan state barunya. Masukkan kembali prediksi dan state ke model untuk terus menghasilkan teks."
      ],
      "metadata": {
        "id": "DOLDAXhzsK4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ],
      "metadata": {
        "id": "ZbPq40WusLVP"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ],
      "metadata": {
        "id": "St57GZ8DsOLi"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jalankan secara berulang untuk menghasilkan beberapa teks. Melihat teks yang dihasilkan, Anda akan melihat model mengetahui kapan harus menggunakan huruf besar, membuat paragraf, dan meniru kosakata menulis seperti Shakespeare. Karena sedikitnya jumlah epoch pelatihan, model belum belajar membentuk kalimat runtut."
      ],
      "metadata": {
        "id": "BdSRmmvXsTfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YJq1fJdsaog",
        "outputId": "5b15d266-246d-4d78-b46b-c2dcf0abc641"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "Resum's not a pawd by a bitter one.\n",
            "\n",
            "GLOUCESTER:\n",
            "My braggs loathing, oven to me sword,\n",
            "You may me mech your steechment. By some pains o' the herd.\n",
            "\n",
            "CUTEBBUST:\n",
            "From when together love.\n",
            "\n",
            "LUCIO:\n",
            "Come on,\n",
            "Stays by up: what's the harmfine shows\n",
            "That Rutland's eyes here's-hardon drubsd I tradule:\n",
            "I'll go the town. ! think I would be drunk, for this joy queen.\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "O world be done!\n",
            "\n",
            "PETRUCHIO:\n",
            "Romeo, the lodders have you not always born:\n",
            "And, do not ruin; though she with lord's hotalary,\n",
            "Are night's dotaly few outward thrilutely:\n",
            "God and Saidou, a shage, which doth fetch thee dead,\n",
            "And I could behold mine bubjers: if thou no'er best\n",
            "Yet benein-doing the place: what haven braved me\n",
            "Where all this pastagabers: why come who hearing as prayers\n",
            "Whereto-day, come on, I swear upon't:\n",
            "Draw me Hastily woes her man;\n",
            "Who is not heir to the sun?\n",
            "\n",
            "ComILLU:\n",
            "But what's the railing steed?\n",
            "\n",
            "Second Lord:\n",
            "But he'r them, noble tcorns.\n",
            "\n",
            "CLARENCE:\n",
            "To wink. Come, here come hither: mountains,\n",
            "Let the m \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 5.485609292984009\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hal termudah yang dapat Anda lakukan untuk meningkatkan hasil adalah dengan melatihnya lebih lama (coba EPOCHS = 30). Anda juga dapat bereksperimen dengan string awal yang berbeda, mencoba menambahkan lapisan RNN lain untuk meningkatkan akurasi model, atau menyesuaikan parameter suhu untuk menghasilkan prediksi yang kurang lebih acak.\n",
        "\n",
        "Jika Anda ingin model menghasilkan teks lebih cepat, hal termudah yang dapat Anda lakukan adalah membuat teks secara batch. Pada contoh di bawah, model menghasilkan 5 keluaran dalam waktu yang hampir sama dengan waktu yang dibutuhkan untuk menghasilkan 1 keluaran di atas."
      ],
      "metadata": {
        "id": "fDgAJBQOsie3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result, '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keVhMs6NsjUM",
        "outputId": "e78c2154-70f7-4b43-98c5-e2221aa012f1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b\"ROMEO:\\nKnock me you so from this fair anchorour?\\n\\nEXETER:\\nSo do I see not mady; now a old.\\n\\nSICINIUS:\\nYea, my nail, lords, to strike me to bright and all expiest.\\n\\nHORTESSS:\\nWho art not hither?\\n\\nMENENIUS:\\nNow me unto the duke, that envitious which now say you mean\\nof your own worse fight will be more than her I.\\n\\nTYBALT:\\nWhat sadst, I'll find enough't me; of all the wars.\\n\\nROMEO:\\nIt must do with sorrow: since it is all shrift;\\nLucentio, she did to come hit her:\\nMutch they say 'Ath.\\n\\nRATCLIFF:\\nFarewell.\\n\\nCLARENCE:\\nAs Muconam,'t I undurst the judgment,\\nAbout it to me atcluse the beck; I\\nleave my pute arrowardiness for. It must out sir.\\n\\nVOLUMNIA:\\nArt thou follow'd that prince\\nAnd will looking his child?\\n\\nDUKE VINCENTIO:\\nBecause manters this ond yet in thy apposition.\\n\\nDUREET:\\nGive me your father will not pay that fee:\\nPersunata is in my brean'd to rise,\\nBut it it not her royar father's time:\\nPmolete and love should become off myself!\\nI'll stay and business it sinks of all my kings.\\n\\nTRANIO:\\nSi\"\n",
            " b\"ROMEO:\\nI thought it finders torch'd upon you bogit.\\nThings Richmond we shall be the lend;\\nYou telling, what comes the design?\\n\\nISABELLA:\\n'Tis blood thou notedops willingly beauty:\\nTill I believe it, overeform dotals, but,\\nBight of good tongue to some dead; help in Bichard's scale in self,\\nAnd give upon 'd scheer for her plainty doth.\\n\\nLORD WILLOUGHBY:\\nHow! rich, come not, I had rather many kings!\\n\\nKATHARINA:\\nWe are well were villain to their fury.\\n\\nSICINIUS:\\nYour sway an hour freets of her,\\nin that surely sent and sloves unto the traitor.\\n\\nROMEO:\\nIf we were put in thy graceful day.\\n\\nCATEMBY:\\nI poar down much and oldesting fast; but\\nOur courtesing or any loss,\\nNot till he seding him over tired,\\nSince that cannot would be here pley'd;\\nLuke that I may quake from my hings' parishly.\\n\\nBAPTISTA:\\nHeavens, trusty Holsays! Past thy gifts fawn; at lions,\\nYou shall be withaconsidins: nor this is nothing.\\nWhat's here? the last, else he deserved Commends.\\nBits he poison be spoil to the heart\\nScarl confer\"\n",
            " b\"ROMEO:\\nSir Whit entioty finds is struck in your highness both.\\n\\nCAPULET:\\nBuck now, thou ridet of, up on the place.\\n\\nCAPULET:\\nPetited, take him is.\\n\\nThARD III:\\nHave you not rest.\\n\\nNORTHUMBERLAND:\\nMardy hath thinketh a treepported heir, I'll be kent to Angelo:\\nIf't he is.\\n\\nOXFORD:\\nLo, now they life, the Duke of Nawness of yours.\\n\\nMARCIUS:\\nGaunt you, if you were safe\\nIn my brother, though court thy faith, where\\nthey have being contented,\\nThan walks the stiring of the dow-herself of death!\\nTo poison, and so doth he is.\\n\\nTYARELLA:\\nThere is for the teeth as he do with deith; I'll lest upon thee.\\nHeavens is the gods do that 'I; by the fresh did speak\\nIf not to me or see now to grace.\\n\\nBUSHY:\\nSadden me, come hither, Ged in the harm appetite.\\nThus, love, none father by the jest,\\nWhich was he done, 'Good master, as him: I retire to his over hither\\nBoth outs of themselves will encourteous death:\\nAnd, to myself to take an old triel England.\\n\\nISABELLA:\\nA boggmant stain son: in heavens be water of veins,\\n\"\n",
            " b\"ROMEO:\\nThere let it serve me well:\\nI'll bow your gracious lord?\\n\\nLADY CAPULET:\\nO woe, what's hang'd and horses more shrud,\\nThere sends our lips of you and not the king.\\n\\nPROSPERO:\\nThe next daughter that at art\\nNothing but secure, sir, he could have beg\\nOnly thruction.\\n\\nROMEO:\\nI told your peace is in thy life, nor powers\\nTo title heard of wilts, ma king have in stockness and\\nThese sword between show us to him; but\\nBut I would tell thee what you shall.\\n\\nFirst WARWICK:\\nIn stars between the duil, to mender it,\\nAs death served, my liqeer oram!\\nGo, sir; for mystery were I; I'll never know yield.\\n\\nHORTENSIO:\\nNow, farhon, I am.\\n\\nLARTIUS:\\nOur ground, Kate were as good to look'd agination and\\nIn quarrel with an advised, stars,--\\n\\nBISTAP:\\nWhat?\\n\\nLORD ROSS:\\nReport you any, good since Mistress Banny,\\nYour husband nor death here that dick'ds in\\nBobours; if he promised his peer:\\nPetruchio her comes of heaven; I would have had ede.\\nTo me as marvect and keep with him.\\n\\nDUKE Ove Dukicor:\\nOne of your mother, I\"\n",
            " b\"ROMEO:\\nIs reckons thore be, thy crown.\\n\\nKING RICHARD II:\\nTo the am constal. There thy dears than him:\\nHis spence: 'tis my insilent, I think, good nowling.\\n\\nLUCENTIO:\\nNone, seely be the field me in the committion\\nThou hast been content: sweet alive being Richmond!\\n\\nMIRANDA:\\nWhy, they Barilence.\\n\\nGARTIN:\\nI'll keep him in: that's safe, the strious weary Past,\\nYou letters fair before her crowned centracy: Most greater\\nWhile we to-knowl kingdom faced of heir,\\nIf not too role, and let my love. But, here is Lucentio?\\n\\nGREMIO:\\nNay, uppose men execution, and dost thought our keeper sour\\nDid ever prattice death! the nature of your father's\\nslain promotions are great dropsing words.\\n\\nGLOUCESTER:\\n\\nVOLUMNIA:\\nI would he browations, itsigh. Is the tongue\\nShovio, still 'hoo much mine anry chose.\\nBut they dare deserred, Northumberland,\\nThat being farther with a wife may be butterl'd thence\\nIn our merciling man or a woman's war.\\n\\nTYBALT:\\nTo see you the music with your country: so we begin.\\n\\nKING EDWARD IV:\\nTh\"], shape=(5,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 11.030964612960815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ekspor Model Generator"
      ],
      "metadata": {
        "id": "osfCUoexs7ev"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model satu langkah ini dapat dengan mudah disimpan dan digunakan kembali, memungkinkan Anda menggunakannya di mana pun tf.saved_model diterima."
      ],
      "metadata": {
        "id": "65-4dGgDs-b3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(one_step_model, 'one_step')\n",
        "one_step_reloaded = tf.saved_model.load('one_step')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZciUsxns875",
        "outputId": "f001081b-747a-48d6-91fe-35ae229ccecc"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7b817651e170>, because it is not built.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUa1Goz4tAA-",
        "outputId": "a6a7f1b5-84e4-4ed8-8288-120154299fcd"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "I any ruin; and is, it so,\n",
            "With what lost-grace is so great tothing, though feasters\n",
            "do spirs of a \n"
          ]
        }
      ]
    }
  ]
}